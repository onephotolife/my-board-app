#!/usr/bin/env python3

"""
DMARCãƒ¬ãƒãƒ¼ãƒˆå—ä¿¡ç¢ºèªãƒ»è‡ªå‹•å‡¦ç†ãƒ„ãƒ¼ãƒ«
ãƒ¡ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ã‹ã‚‰DMARCãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—ã—ã€è‡ªå‹•çš„ã«è§£æ
"""

import os
import sys
import imaplib
import email
import gzip
import zipfile
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from typing import List, Dict, Tuple
import json
import argparse
import tempfile
import shutil

class DMARCReportChecker:
    def __init__(self, config: Dict):
        self.config = config
        self.reports_dir = config.get('reports_dir', 'dmarc-reports')
        self.processed_dir = os.path.join(self.reports_dir, 'processed')
        self.stats = {
            'total_reports': 0,
            'new_reports': 0,
            'processed_reports': 0,
            'failed_reports': 0,
            'senders': {},
            'date_range': {'earliest': None, 'latest': None}
        }
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(self.reports_dir, exist_ok=True)
        os.makedirs(self.processed_dir, exist_ok=True)
    
    def check_local_reports(self) -> List[str]:
        """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯"""
        report_files = []
        
        for root, dirs, files in os.walk(self.reports_dir):
            # processedãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ã‚¹ã‚­ãƒƒãƒ—
            if 'processed' in root:
                continue
                
            for file in files:
                if file.endswith(('.xml', '.xml.gz', '.zip')):
                    filepath = os.path.join(root, file)
                    report_files.append(filepath)
                    self.stats['total_reports'] += 1
        
        return report_files
    
    def extract_report(self, filepath: str) -> str:
        """åœ§ç¸®ã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã‚’å±•é–‹"""
        content = None
        
        try:
            if filepath.endswith('.gz'):
                with gzip.open(filepath, 'rt', encoding='utf-8') as f:
                    content = f.read()
            elif filepath.endswith('.zip'):
                with zipfile.ZipFile(filepath, 'r') as z:
                    for name in z.namelist():
                        if name.endswith('.xml'):
                            content = z.read(name).decode('utf-8')
                            break
            else:  # Plain XML
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {filepath} ã®å±•é–‹ã«å¤±æ•—: {e}")
            self.stats['failed_reports'] += 1
        
        return content
    
    def parse_report_metadata(self, xml_content: str) -> Dict:
        """XMLãƒ¬ãƒãƒ¼ãƒˆã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        metadata = {
            'org_name': None,
            'email': None,
            'report_id': None,
            'date_begin': None,
            'date_end': None,
            'domain': None,
            'policy': None,
            'total_messages': 0,
            'pass_count': 0,
            'fail_count': 0
        }
        
        try:
            root = ET.fromstring(xml_content)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³
            report_metadata = root.find('report_metadata')
            if report_metadata is not None:
                org_name = report_metadata.find('org_name')
                if org_name is not None:
                    metadata['org_name'] = org_name.text
                
                email_elem = report_metadata.find('email')
                if email_elem is not None:
                    metadata['email'] = email_elem.text
                
                report_id = report_metadata.find('report_id')
                if report_id is not None:
                    metadata['report_id'] = report_id.text
                
                date_range = report_metadata.find('date_range')
                if date_range is not None:
                    begin = date_range.find('begin')
                    end = date_range.find('end')
                    if begin is not None:
                        metadata['date_begin'] = int(begin.text)
                    if end is not None:
                        metadata['date_end'] = int(end.text)
            
            # ãƒãƒªã‚·ãƒ¼æƒ…å ±
            policy = root.find('policy_published')
            if policy is not None:
                domain = policy.find('domain')
                if domain is not None:
                    metadata['domain'] = domain.text
                
                p = policy.find('p')
                if p is not None:
                    metadata['policy'] = p.text
            
            # ãƒ¬ã‚³ãƒ¼ãƒ‰çµ±è¨ˆ
            for record in root.findall('record'):
                row = record.find('row')
                if row is not None:
                    count = row.find('count')
                    if count is not None:
                        count_val = int(count.text)
                        metadata['total_messages'] += count_val
                        
                        policy_evaluated = row.find('policy_evaluated')
                        if policy_evaluated is not None:
                            dkim = policy_evaluated.find('dkim')
                            spf = policy_evaluated.find('spf')
                            
                            if dkim is not None and spf is not None:
                                if dkim.text == 'pass' and spf.text == 'pass':
                                    metadata['pass_count'] += count_val
                                else:
                                    metadata['fail_count'] += count_val
            
        except ET.ParseError as e:
            print(f"XMLãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        
        return metadata
    
    def analyze_reports(self, report_files: List[str]) -> None:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’åˆ†æ"""
        print("\nğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆåˆ†æ")
        print("=" * 60)
        
        for filepath in report_files:
            print(f"\nğŸ“„ å‡¦ç†ä¸­: {os.path.basename(filepath)}")
            
            # ãƒ¬ãƒãƒ¼ãƒˆå±•é–‹
            content = self.extract_report(filepath)
            if not content:
                continue
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è§£æ
            metadata = self.parse_report_metadata(content)
            
            if metadata['org_name']:
                # é€ä¿¡å…ƒçµ±è¨ˆ
                sender = metadata['org_name']
                if sender not in self.stats['senders']:
                    self.stats['senders'][sender] = {
                        'count': 0,
                        'messages': 0,
                        'pass': 0,
                        'fail': 0
                    }
                
                self.stats['senders'][sender]['count'] += 1
                self.stats['senders'][sender]['messages'] += metadata['total_messages']
                self.stats['senders'][sender]['pass'] += metadata['pass_count']
                self.stats['senders'][sender]['fail'] += metadata['fail_count']
                
                # æ—¥ä»˜ç¯„å›²æ›´æ–°
                if metadata['date_begin']:
                    date_begin = datetime.fromtimestamp(metadata['date_begin'])
                    if not self.stats['date_range']['earliest'] or \
                       date_begin < self.stats['date_range']['earliest']:
                        self.stats['date_range']['earliest'] = date_begin
                
                if metadata['date_end']:
                    date_end = datetime.fromtimestamp(metadata['date_end'])
                    if not self.stats['date_range']['latest'] or \
                       date_end > self.stats['date_range']['latest']:
                        self.stats['date_range']['latest'] = date_end
                
                # ãƒ¬ãƒãƒ¼ãƒˆè©³ç´°è¡¨ç¤º
                print(f"  ğŸ“ é€ä¿¡å…ƒ: {metadata['org_name']}")
                print(f"  ğŸ“… æœŸé–“: {datetime.fromtimestamp(metadata['date_begin']).strftime('%Y-%m-%d')} - "
                      f"{datetime.fromtimestamp(metadata['date_end']).strftime('%Y-%m-%d')}")
                print(f"  ğŸ“§ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {metadata['total_messages']:,}")
                print(f"  âœ… èªè¨¼æˆåŠŸ: {metadata['pass_count']:,}")
                print(f"  âŒ èªè¨¼å¤±æ•—: {metadata['fail_count']:,}")
                
                if metadata['total_messages'] > 0:
                    pass_rate = (metadata['pass_count'] / metadata['total_messages']) * 100
                    print(f"  ğŸ“ˆ æˆåŠŸç‡: {pass_rate:.1f}%")
                
                self.stats['processed_reports'] += 1
            
            # å‡¦ç†æ¸ˆã¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ç§»å‹•ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            # shutil.move(filepath, os.path.join(self.processed_dir, os.path.basename(filepath)))
    
    def generate_summary(self) -> str:
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = []
        report.append("\n" + "=" * 70)
        report.append("ğŸ“Š DMARCãƒ¬ãƒãƒ¼ãƒˆå—ä¿¡çŠ¶æ³ã‚µãƒãƒªãƒ¼")
        report.append("=" * 70)
        report.append("")
        
        # åŸºæœ¬çµ±è¨ˆ
        report.append("ã€ãƒ¬ãƒãƒ¼ãƒˆçµ±è¨ˆã€‘")
        report.append(f"ç·ãƒ¬ãƒãƒ¼ãƒˆæ•°: {self.stats['total_reports']}")
        report.append(f"å‡¦ç†æ¸ˆã¿: {self.stats['processed_reports']}")
        report.append(f"å‡¦ç†å¤±æ•—: {self.stats['failed_reports']}")
        report.append("")
        
        # æœŸé–“
        if self.stats['date_range']['earliest'] and self.stats['date_range']['latest']:
            report.append("ã€ãƒ‡ãƒ¼ã‚¿æœŸé–“ã€‘")
            report.append(f"æœ€å¤: {self.stats['date_range']['earliest'].strftime('%Y-%m-%d %H:%M')}")
            report.append(f"æœ€æ–°: {self.stats['date_range']['latest'].strftime('%Y-%m-%d %H:%M')}")
            
            # æœŸé–“è¨ˆç®—
            days_covered = (self.stats['date_range']['latest'] - 
                          self.stats['date_range']['earliest']).days + 1
            report.append(f"ã‚«ãƒãƒ¼æœŸé–“: {days_covered}æ—¥é–“")
            report.append("")
        
        # é€ä¿¡å…ƒåˆ¥çµ±è¨ˆ
        if self.stats['senders']:
            report.append("ã€é€ä¿¡å…ƒåˆ¥çµ±è¨ˆã€‘")
            report.append("-" * 60)
            report.append(f"{'é€ä¿¡å…ƒ':<25} {'ãƒ¬ãƒãƒ¼ãƒˆ':>8} {'ãƒ¡ãƒ¼ãƒ«æ•°':>10} {'æˆåŠŸç‡':>8}")
            report.append("-" * 60)
            
            for sender, data in sorted(self.stats['senders'].items(), 
                                      key=lambda x: x[1]['messages'], 
                                      reverse=True):
                if data['messages'] > 0:
                    pass_rate = (data['pass'] / data['messages']) * 100
                else:
                    pass_rate = 0
                
                sender_display = sender[:23] + ".." if len(sender) > 25 else sender
                report.append(f"{sender_display:<25} {data['count']:>8} "
                            f"{data['messages']:>10,} {pass_rate:>7.1f}%")
            
            report.append("-" * 60)
            
            # ç·è¨ˆ
            total_messages = sum(s['messages'] for s in self.stats['senders'].values())
            total_pass = sum(s['pass'] for s in self.stats['senders'].values())
            total_fail = sum(s['fail'] for s in self.stats['senders'].values())
            
            if total_messages > 0:
                overall_pass_rate = (total_pass / total_messages) * 100
            else:
                overall_pass_rate = 0
            
            report.append(f"{'ç·è¨ˆ':<25} {self.stats['total_reports']:>8} "
                        f"{total_messages:>10,} {overall_pass_rate:>7.1f}%")
            report.append("")
            
            # è©•ä¾¡
            report.append("ã€ç·åˆè©•ä¾¡ã€‘")
            if overall_pass_rate >= 99:
                report.append("âœ… èªè¨¼ç‡99%ä»¥ä¸Š - Phase 5 (reject) ã¸ã®ç§»è¡Œã‚’æ¤œè¨å¯èƒ½")
            elif overall_pass_rate >= 95:
                report.append("âœ… èªè¨¼ç‡95%ä»¥ä¸Š - æ¬¡ã®ãƒ•ã‚§ãƒ¼ã‚ºã¸ã®ç§»è¡Œã‚’æ¤œè¨å¯èƒ½")
            elif overall_pass_rate >= 90:
                report.append("âš ï¸  èªè¨¼ç‡90%ä»¥ä¸Š - æ”¹å–„ã®ä½™åœ°ã‚ã‚Š")
            else:
                report.append("âŒ èªè¨¼ç‡90%æœªæº€ - å•é¡Œã®èª¿æŸ»ã¨ä¿®æ­£ãŒå¿…è¦")
        else:
            report.append("ãƒ¬ãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            report.append("")
            report.append("ã€ç¢ºèªäº‹é …ã€‘")
            report.append("1. DMARCãƒ¬ã‚³ãƒ¼ãƒ‰ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹")
            report.append("2. ãƒ¬ãƒãƒ¼ãƒˆç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒæœ‰åŠ¹ã‹")
            report.append("3. 24-48æ™‚é–“çµŒéã—ã¦ã„ã‚‹ã‹")
        
        report.append("")
        report.append("=" * 70)
        
        return '\n'.join(report)
    
    def check_recent_reports(self, days: int = 7) -> None:
        """æœ€è¿‘ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯"""
        print(f"\nğŸ” éå»{days}æ—¥é–“ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç¢ºèªä¸­...")
        
        cutoff_date = datetime.now() - timedelta(days=days)
        recent_count = 0
        
        for filepath in self.check_local_reports():
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ—¥æ™‚ã‚’ç¢ºèª
            mtime = datetime.fromtimestamp(os.path.getmtime(filepath))
            if mtime >= cutoff_date:
                recent_count += 1
        
        if recent_count > 0:
            print(f"âœ… {recent_count}å€‹ã®æ–°ã—ã„ãƒ¬ãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        else:
            print(f"âš ï¸  éå»{days}æ—¥é–“ã®æ–°ã—ã„ãƒ¬ãƒãƒ¼ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“")
            print("\nã€ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã€‘")
            print("1. ãƒ¡ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            print("2. ã‚¹ãƒ‘ãƒ ãƒ•ã‚©ãƒ«ãƒ€ã‚‚ç¢ºèªã—ã¦ãã ã•ã„")
            print("3. DMARCãƒ¬ã‚³ãƒ¼ãƒ‰ã®ruaã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„")

def main():
    parser = argparse.ArgumentParser(description='DMARCãƒ¬ãƒãƒ¼ãƒˆå—ä¿¡ç¢ºèªãƒ„ãƒ¼ãƒ«')
    parser.add_argument('--dir', default='dmarc-reports', 
                       help='ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: dmarc-reportsï¼‰')
    parser.add_argument('--days', type=int, default=7,
                       help='ç¢ºèªã™ã‚‹æ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 7ï¼‰')
    parser.add_argument('--json', action='store_true',
                       help='JSONå½¢å¼ã§å‡ºåŠ›')
    parser.add_argument('--save', help='çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜')
    
    args = parser.parse_args()
    
    # è¨­å®š
    config = {
        'reports_dir': args.dir
    }
    
    # ãƒã‚§ãƒƒã‚«ãƒ¼åˆæœŸåŒ–
    checker = DMARCReportChecker(config)
    
    print("=" * 70)
    print("ğŸ” DMARCãƒ¬ãƒãƒ¼ãƒˆå—ä¿¡ç¢ºèªãƒ„ãƒ¼ãƒ«")
    print("=" * 70)
    print(f"ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.dir}")
    print(f"ç¢ºèªæœŸé–“: éå»{args.days}æ—¥é–“")
    
    # æœ€è¿‘ã®ãƒ¬ãƒãƒ¼ãƒˆç¢ºèª
    checker.check_recent_reports(args.days)
    
    # ãƒ¬ãƒãƒ¼ãƒˆåˆ†æ
    report_files = checker.check_local_reports()
    if report_files:
        checker.analyze_reports(report_files)
    
    # ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
    summary = checker.generate_summary()
    
    if args.json:
        # JSONå‡ºåŠ›
        json_output = {
            'stats': checker.stats,
            'timestamp': datetime.now().isoformat()
        }
        # datetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        if checker.stats['date_range']['earliest']:
            json_output['stats']['date_range']['earliest'] = \
                checker.stats['date_range']['earliest'].isoformat()
        if checker.stats['date_range']['latest']:
            json_output['stats']['date_range']['latest'] = \
                checker.stats['date_range']['latest'].isoformat()
        
        print("\n" + json.dumps(json_output, indent=2, ensure_ascii=False))
    else:
        print(summary)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    if args.save:
        with open(args.save, 'w', encoding='utf-8') as f:
            f.write(summary)
            if args.json:
                f.write("\n\n--- JSON ---\n")
                f.write(json.dumps(json_output, indent=2, ensure_ascii=False))
        print(f"\nçµæœã‚’ {args.save} ã«ä¿å­˜ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()